{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter11_ver2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "EPIBtljLEvLF",
        "DAbjI17bEvLN",
        "MgEVSTdWEvLN",
        "pvI_QUV2EvLZ",
        "r0UrIaE6EvLZ",
        "nPYTuIt5EvLd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ka201504/scipy_2015_sklearn_tutorial/blob/master/Chapter11_ver2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JSstnz3GEvEy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 11 機械学習の基礎（教師あり学習）"
      ]
    },
    {
      "metadata": {
        "id": "4d9CszE7EvE0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- **[11.1 機械学習の全体像](#11.1-機械学習の全体像)**\n",
        "    - [11.1.1 機械学習とは？](#11.1.1-機械学習とは？)\n",
        "    - [11.1.2 教師あり学習](#11.1.2-教師あり学習)\n",
        "    - [11.1.3 教師なし学習](#11.1.3-教師なし学習)\n",
        "    - [11.1.4 強化学習](#11.1.4-強化学習)\n",
        "<br><br>\n",
        "- **[11.2 重回帰分析](#11.2-重回帰分析)** \n",
        "<br><br>\n",
        "- **[11.3 ロジスティック回帰分析](#11.3-ロジスティック回帰分析)** \n",
        "<br><br>\n",
        "- **[11.4 正則化、ラッソ回帰、リッジ回帰](#11.4-正則化、ラッソ回帰、リッジ回帰)** \n",
        "<br><br>\n",
        "- **[11.5 決定木](#11.5-決定木)** \n",
        "<br><br>\n",
        "- **[11.6 k-NN](#11.6-k-NN)** \n",
        "<br><br>\n",
        "- **[11.7 サポートベクターマシン](#11.7-サポートベクターマシン)** \n",
        "<br><br>\n",
        "- **[11.8 総合問題](#11.8-総合問題)**\n",
        "    - [11.8.1 総合問題1](#11.8.1-総合問題1)\n",
        "    - [11.8.2 総合問題2](#11.8.2-総合問題2)\n",
        "    - [11.8.3 総合問題3](#11.8.3-総合問題3)"
      ]
    },
    {
      "metadata": {
        "id": "ySCWqWTHEvE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.1 機械学習の全体像\n",
        "ゴール：機械学習の各アプローチ（教師あり学習、教師なし学習）と概要を知ること"
      ]
    },
    {
      "metadata": {
        "id": "CqlAvZfDEvE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e4cd080-ae48-47e3-c372-db3598804f51"
      },
      "cell_type": "code",
      "source": [
        "# 途中で使用するため、あらかじめ読み込んでおいてください。\n",
        "# データ加工・処理・分析モジュール\n",
        "import numpy as np\n",
        "import numpy.random as random\n",
        "import scipy as sp\n",
        "from pandas import Series, DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# 可視化モジュール\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# 機械学習モジュール\n",
        "import sklearn\n",
        "\n",
        "# 小数第３まで表示\n",
        "%precision 3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%.3f'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "BxhfYIzeEvFB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.1.1 機械学習とは？\n",
        "キーワード：機械学習、教師あり学習、教師なし学習、強化学習"
      ]
    },
    {
      "metadata": {
        "id": "uNbhjJYXEvFD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "いよいよここから機械学習の章になります。これまで様々なデータを見てきました。そのデータの中から、モデルを構築し、ある値を予測をしたりグループ分けしたりするのが**機械学習**です。\n",
        "\n",
        "機械学習は主に3つに分けられることが多く、**教師あり学習(supervised learning)**、**教師なし学習(unsupervised learning)**、**強化学習(reinforcement learning)**に分けられます。（この分け方以外にも、教師あり学習と教師なし学習の2つに分けたり、上の3つに半教師あり学習を加えて4つに分けてあることもありますが、ここでは3つに分けて考えることにします。）\n",
        "\n",
        "まずは、教師あり学習です。これは、その名の通り、教師が与えられて、その状態・データからモデルを構築します。目的がはっきりしている場合で、目的型学習とも言われます。訓練データ（学習データ）があり、そこから目的の変数（アウトプット）を予測するために説明変数を使ってモデルを構築する方法です。色々な手法があり、後ほど説明します。\n",
        "\n",
        "一方、教師なし学習は、目的がなく、データの構造から傾向を見る方法をいいます。ゴールがはっきりしておらず、試行錯誤しながらするやり方です。探索型のデータ分析とも言われます。\n",
        "\n",
        "以下は、教師あり学習と教師なし学習のイメージです。左図が教師あり学習で、あらかじめラベル付け（以下は丸とバツ）がされていて、丸とバツに分けたいというモチベーションがあります。例えば、x1とx2の2つの軸を持つデータが与えられてプロットし、それが丸なのかバツなのかを予測します。一方、右図が教師なし学習で、ラベル付けは特にされておらず、与えられたデータ構造からインサイト（以下の赤丸に囲まれているグループが2つできそうだ）を見つけ出していきます。"
      ]
    },
    {
      "metadata": {
        "id": "Dor753IkEvFD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](http://oliviaklose.azurewebsites.net/content/images/2015/02/2-supervised-vs-unsupervised-1.png)"
      ]
    },
    {
      "metadata": {
        "id": "GPA-24X0EvFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL:http://oliviaklose.azurewebsites.net/content/images/2015/02/2-supervised-vs-unsupervised-1.png"
      ]
    },
    {
      "metadata": {
        "id": "D42ZKLATEvFG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "そして、3つ目の強化学習も最近注目されており、面白い分野なのですが、ここでは紹介するだけにとどめ、主に教師あり学習と教師なし学習を中心に学んでいきます。"
      ]
    },
    {
      "metadata": {
        "id": "aXKGYjbNEvFH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、今回の章で扱うデータ分析は、いきなり機械学習を適応するところから始めます。簡単に機械学習を使えることを体感していただきたいからです。ただし、実際に本番でデータ分析をするときには、どんなデータがあるのか細かくチェックしたり、基本統計量やヒストグラム、散布図の作成など、探索的にデータを観察することは必ず実施してください。そういった簡単なデータ探索から色々なことがわかったりすることがあるからです。ビジネスの現場で、無理に機械学習をあてはめる必要はありません。もちろん、機械学習を通して有益な示唆や収益源が見つかることもあるので、手法の使い分けが重要です。"
      ]
    },
    {
      "metadata": {
        "id": "64OK12B9EvFJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**[ポイント]**\n",
        "\n",
        ">現場でデータ分析をするときは、機械学習を適応する前に、基本統計量や散布図を作成し、データの傾向や全体像を抑えましょう。"
      ]
    },
    {
      "metadata": {
        "id": "MNL5z4XCEvFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参考ですが、機械学習の易しめの本としては、以下の文献やURLが参考になりますので、この章の良い予習・復習になります。"
      ]
    },
    {
      "metadata": {
        "id": "hIf-iDnoEvFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考文献]\n",
        "\n",
        ">『Pythonによる機械学習入門』（株式会社システム計画研究所 (編集)、オーム社）\n",
        "\n",
        ">『Introduction to Machine Learning with Python』（Andreas C.Muller & Sarah Guido、O'REILLY）\n",
        "\n",
        ">『ゼロからはじめるデータサイエンス ―Pythonで学ぶ基本と実践』（Joel Grus (著), 菊池 彰 (翻訳)、O'REILLY）\n",
        "\n",
        ">[参考URL]\n",
        "\n",
        ">https://github.com/jakevdp/PythonDataScienceHandbook"
      ]
    },
    {
      "metadata": {
        "id": "d83ArSaYEvFN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また、この章では主に、Pythonのscikit-learn（サイキットラーン）を使います。以前、回帰分析の章で少し使いました。以下のサイトに、scikit-learnの詳細な情報や使い方がありますので、この講座が終わった後は是非読んでみてください。"
      ]
    },
    {
      "metadata": {
        "id": "MT2bxUoxEvFO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考URL]\n",
        "\n",
        ">http://scikit-learn.org/stable/index.html"
      ]
    },
    {
      "metadata": {
        "id": "uaiOx0HpEvFQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ビジネス的な視点で機械学習（とデータサイエンス）を活かすことを学ぶには以下のものが良いです。URLには色々な資料等あるようなので、参考にしてください。"
      ]
    },
    {
      "metadata": {
        "id": "WCEp5CjJEvFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考文献]\n",
        "\n",
        ">『戦略的データサイエンス入門 ―ビジネスに活かすコンセプトとテクニック』（Foster Provost (著), Tom Fawcett (著), 竹田 正和(監訳) (翻訳), 古畠 敦 (翻訳), & 8 その他、オライリージャパン）\n",
        "\n",
        ">[参考URL]\n",
        "\n",
        ">http://www.data-science-for-biz.com/DSB/Home.html"
      ]
    },
    {
      "metadata": {
        "id": "7_P1CEOnEvFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.1.2 教師あり学習\n",
        "キーワード：目的変数、説明変数、回帰、分類"
      ]
    },
    {
      "metadata": {
        "id": "Oi0pyZjmEvFT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずは簡単に教師あり学習について紹介します。先ほど説明したように、あらかじめ教師データと言われる見本が与えられており、それをベースにモデルを構築します。データのカラム（変数）について、ゴールとなる予測したい変数のことを**目的変数**と言います（他の名称としては、応答変数、ターゲット変数、従属変数とも言われます）。関数y=f(x)でいうところのyにあたります。一方、その目的変数を説明するための変数xのことを**説明変数**と言います（他には予測変数だったり、独立変数と言われることもありますので注意してください）。\n",
        "\n",
        "具体的には、ある消費財について、購買者が離反するかどうか（目的変数）を予測したい時に、過去の色々なデータ（属性、購買頻度、関連商品の購入など）を説明変数としてモデリングします。"
      ]
    },
    {
      "metadata": {
        "id": "8ktXCrWVEvFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "目的変数については、それが数値の場合だったり、どのグループに属するのか予測したい場合があります。数値の場合は**回帰**、何かのグループに分ける時どのグループに属するのか分けるのが**分類**といいます。この講座ではどちらのデータも扱っていきます。教師あり学習の手法としては、**重回帰分析、ロジスティック回帰分析、k近傍法、決定木、サポートベクターマシン、ランダムフォレスト**等があります。\n",
        "\n",
        "なお、目的にもよりますが、ビジネスの現場では、重回帰分析、ロジスティック回帰分析、決定木がメインで使われます。サポートベクターマシンなどは説明がしにくく、一般の人が1回聞いてすぐに理解出来る手法ではありません（さらに、機械学習で「決定木」は理解しやすいという記載が多々ありますが、これもなかなか一般の人が聞いてすぐに理解出来る概念ではないです）。また後で検証結果をお見せしますが、いろいろな手法を使っても予測精度などはそれほど大きくは変わらないことも多々あります。そのため、第3者にとって理解がしやすく、アクションを実施しやすいものを選んだ方が良いこともあります。ただ、例えば、その予測精度が1％改善するだけで、ビジネスインパクトが大きい場合は、手法の選択が肝心になってきます。ケースバイケースで判断して使ってください。"
      ]
    },
    {
      "metadata": {
        "id": "L1iRwnYkEvFV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.1.3 教師なし学習\n",
        "キーワード：クラスタリング、主成分分析、アソシエーションルール"
      ]
    },
    {
      "metadata": {
        "id": "1oyQeqeoEvFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次は、教師なし学習です。教師なし学習は、見本（インプットとアウトプットの関係）を与えられておらず、目的がはっきりしていないケースを扱います。与えられた情報をインプットとして、クラス分けをします。そのデータ構造を調べることで、意味のある情報を取り出します。主な手法としては、**クラスター分析（クラスタリング）**があります。実務的な利用方法としては、ある消費者がどんなグループに分かれるのか（**セグメンテーション**）など、マーケティング分析を実施する時によく使われます。他、過去の事例が役に立たない場合（詐欺行為、異常値発見など）にも使われたります。なお、クラスタリングは、先ほど説明した教師あり学習における分類と似たような言葉なのですが、分類はあくまで目的があります（どちらのグループに分かれるのか）ので、ここでのセグメンテーションはあくまでターゲットがわからないケースを想定します。"
      ]
    },
    {
      "metadata": {
        "id": "vK0XQfmAEvFq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、クラスタリングは、目的となる変数が設定されていないため、探索的なデータ分析でもあります。クラスタリング結果に基づいてセグメンテーションなどでグルーピングをしたら終わりではなく、そこから深堀をしたり、現場の感覚とズレがないかなど見ていく必要があります。計算はすぐにできますが、その後の計算結果の利用や解釈には、直感的なアプローチも必要です。完全には自動化できず、人の判断が重要な役割を担ってきます。"
      ]
    },
    {
      "metadata": {
        "id": "9SRSxiewEvFr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "他の教師なし学習としては、**主成分分析（次元圧縮）**、**アソシエーションルール**などがあります。主成分分析は、変数が多い時に、それらの情報を凝縮して、変数を減らす方法です。アソシエーションルールはPOS（Point of Sales）といわれる購買データ等の分析に使われ、ある商品Aを買っている人はある商品Bも買っていることが多いというのが、このアプローチからわかったりします。"
      ]
    },
    {
      "metadata": {
        "id": "9qKFhZg0EvFs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以下の参考文献では、おおまかではありますが、教師あり学習を「目的志向的データマイニング」、教師なし学習を「探索的データマイニング」としており、ビジネスの現場でどのように機械学習やデータマイニングを使っていけば良いか記載されています。ビジネス視点でこの講座を活かしたい場合はオススメです。なお、下記の参考文献のうち、上2つは翻訳本で、原書の一部分がカットされていますので、英語が読める方は原書が良いでしょう。"
      ]
    },
    {
      "metadata": {
        "id": "ccMf_6S7EvFu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考文献]\n",
        "\n",
        ">『データマイニング手法 予測・スコアリング編―営業、マーケティング、CRMのための顧客分析』（ゴードン S.リノフ (著), マイケル J.A.ベリー (著), 江原 淳 (翻訳), 上野 勉 (翻訳), & 2 その他、海文堂出版）\n",
        "\n",
        ">『データマイニング手法 探索的知識発見編―営業、マーケティング、CRMのための顧客分析』（ゴードン S.リノフ (著), マイケル J.A.ベリー (著), 江原 淳 (翻訳), 上野 勉 (翻訳), & 2 その他、海文堂出版）\n",
        "\n",
        ">『Data Mining Techniques: For Marketing, Sales, and Customer Relationship Management 』（Gordon S. Linoff (著), Michael J. A. Berry (著),Wiley）"
      ]
    },
    {
      "metadata": {
        "id": "nF3rV70PEvFv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.1.4 強化学習\n",
        "キーワード：動的計画法、モンテカルロ法、TD学習、OpenAI"
      ]
    },
    {
      "metadata": {
        "id": "bGPDA9lwEvFw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "強化学習とは、ある報酬を最大化するために、何をすべきかを学習します。教師あり学習のように、最適な出力等は教えられず、その代わり、どのような行動を取ったら、より大きな報酬を得られるかを見つけ出します。環境が与えられて、その中から学習をしていきます。具体的なイメージとしては、赤ちゃんは歩き方を教わっていないのに、自分がおかれている環境の中から試行錯誤しながら歩けるようになるというイメージです。"
      ]
    },
    {
      "metadata": {
        "id": "c4CmXhjOEvFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "教師あり学習との違いは、探索的に行動し、相互作用の中から学んでいくという点です。探索と知識利用の間のトレードオフをどのように扱うかがこの強化学習のテーマでもあります。"
      ]
    },
    {
      "metadata": {
        "id": "dco5IorsEvFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "強化学習の主なアプローチとしては、動的計画法、モンテカルロ法やTD学習などがあります。動的計画法は、明示的な知識があることを仮定しています。一方、モンテカルロ法は、環境における完全な知識を必要とせず、経験のみを必要とする方法です。TD学習は、最適問題を反復計算により数値的に解く方法の1つで、本講座の後半で学ぶ勾配法の考え方に基づいています。"
      ]
    },
    {
      "metadata": {
        "id": "7v4i2BWpEvFz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "この講座では強化学習の紹介のみで終わりになりますが、興味のある方は、以下の参考文献やOpenAIのサイトなどを見てください。"
      ]
    },
    {
      "metadata": {
        "id": "rcx-GPVSEvF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考文献]\n",
        "\n",
        ">『強化学習』（Richard S. Sutton and Andrew G.Barto、三上・皆川共訳、森北出版株式会社）\n",
        "\n",
        "\n",
        "\n",
        ">[参考URL]\n",
        "\n",
        ">https://gym.openai.com"
      ]
    },
    {
      "metadata": {
        "id": "A18guefFEvF3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.2 重回帰分析\n",
        "ゴール：目的変数、説明変数、多重共線性、変数選択法"
      ]
    },
    {
      "metadata": {
        "id": "yU60jgvCEvF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "教師あり学習の1つ目は、**重回帰分析**について学びます。以前、この講座で単回帰分析について扱いました(第3章を参照)。目的変数に対して説明変数は1つで、sklearnを使ってモデルを構築しました。この考え方を広げて、目的変数に影響を与えている説明変数は1つではなく複数あるのではないかと考えるのが重回帰分析です。以下は重回帰分析のイメージです。"
      ]
    },
    {
      "metadata": {
        "id": "4YBNjbVmEvF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](http://diary-ba.up.n.seesaa.net/diary-ba/image/E9878DE59B9EE5B8B0E5BC8FE383A2E38387E383AB.png?d=a1)"
      ]
    },
    {
      "metadata": {
        "id": "1-LXLp1xEvF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL:http://diary-ba.up.n.seesaa.net/diary-ba/image/E9878DE59B9EE5B8B0E5BC8FE383A2E38387E383AB.png?d=a1"
      ]
    },
    {
      "metadata": {
        "id": "hnyNB_DFEvF9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "具体的なデータを用いて、この重回帰分析を使ってみます。まずは、自動車の価格データとそれらの属性（自動車の大きさなど）データをウェブ上から取得しましょう。目的としては、この自動車の価格を予測するモデルを構築します。"
      ]
    },
    {
      "metadata": {
        "id": "IogSlcuXEvF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 自動車価格データの取得\n",
        "import requests, zipfile\n",
        "from io import StringIO\n",
        "import io\n",
        "\n",
        "# url \n",
        "auto_data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "s = requests.get(auto_data_url).content\n",
        "auto_data = pd.read_csv(io.StringIO(s.decode('utf-8')),header=None)\n",
        "auto_data.columns =[\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\"\n",
        "                     ,\"aspiration\",\"num-of-doors\",\"body-style\",\"drive-wheels\",\"engine-location\",\"wheel-base\",\"length\"\n",
        "                   ,\"width\",\"height\",\"curb-weight\",\"engine-type\",\"num-of-cylinders\",\"engine-size\",\"fuel-system\"\n",
        "                    ,\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8AKe_hbEvGC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "いつも通り、簡単にデータを見てみましょう。head()を使いました。よくみてみると、このデータの中に?があるため、このままではモデリングがやりくいです。"
      ]
    },
    {
      "metadata": {
        "id": "AqJHQrGxEvGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "1b428b78-2eb1-446e-85ec-8c781f00e19f"
      },
      "cell_type": "code",
      "source": [
        "auto_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>normalized-losses</th>\n",
              "      <th>make</th>\n",
              "      <th>fuel-type</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>num-of-doors</th>\n",
              "      <th>body-style</th>\n",
              "      <th>drive-wheels</th>\n",
              "      <th>engine-location</th>\n",
              "      <th>wheel-base</th>\n",
              "      <th>...</th>\n",
              "      <th>engine-size</th>\n",
              "      <th>fuel-system</th>\n",
              "      <th>bore</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compression-ratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peak-rpm</th>\n",
              "      <th>city-mpg</th>\n",
              "      <th>highway-mpg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>...</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>13495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>?</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>convertible</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>88.6</td>\n",
              "      <td>...</td>\n",
              "      <td>130</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.47</td>\n",
              "      <td>2.68</td>\n",
              "      <td>9.0</td>\n",
              "      <td>111</td>\n",
              "      <td>5000</td>\n",
              "      <td>21</td>\n",
              "      <td>27</td>\n",
              "      <td>16500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>alfa-romero</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>hatchback</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>94.5</td>\n",
              "      <td>...</td>\n",
              "      <td>152</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>2.68</td>\n",
              "      <td>3.47</td>\n",
              "      <td>9.0</td>\n",
              "      <td>154</td>\n",
              "      <td>5000</td>\n",
              "      <td>19</td>\n",
              "      <td>26</td>\n",
              "      <td>16500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>...</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>...</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   symboling normalized-losses         make fuel-type aspiration num-of-doors  \\\n",
              "0          3                 ?  alfa-romero       gas        std          two   \n",
              "1          3                 ?  alfa-romero       gas        std          two   \n",
              "2          1                 ?  alfa-romero       gas        std          two   \n",
              "3          2               164         audi       gas        std         four   \n",
              "4          2               164         audi       gas        std         four   \n",
              "\n",
              "    body-style drive-wheels engine-location  wheel-base  ...    engine-size  \\\n",
              "0  convertible          rwd           front        88.6  ...            130   \n",
              "1  convertible          rwd           front        88.6  ...            130   \n",
              "2    hatchback          rwd           front        94.5  ...            152   \n",
              "3        sedan          fwd           front        99.8  ...            109   \n",
              "4        sedan          4wd           front        99.4  ...            136   \n",
              "\n",
              "   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n",
              "0         mpfi  3.47    2.68               9.0        111      5000       21   \n",
              "1         mpfi  3.47    2.68               9.0        111      5000       21   \n",
              "2         mpfi  2.68    3.47               9.0        154      5000       19   \n",
              "3         mpfi  3.19    3.40              10.0        102      5500       24   \n",
              "4         mpfi  3.19    3.40               8.0        115      5500       18   \n",
              "\n",
              "  highway-mpg  price  \n",
              "0          27  13495  \n",
              "1          27  16500  \n",
              "2          26  16500  \n",
              "3          30  13950  \n",
              "4          22  17450  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "oWibvvVTEvGI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、データを確保しておくために、csvファイルとして保存しておきましょう。to_csvを使います。"
      ]
    },
    {
      "metadata": {
        "id": "n5_qWcuLEvGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auto_data.to_csv('auto_data.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPiCaMzBEvGN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "今回の目的はpriceを予測することなので、このpriceにある?データは削除してしまいましょう。pandasで学んだテクニックを使います。また、説明変数はhorsepower、width、heightの3つを使うことにしましょう。"
      ]
    },
    {
      "metadata": {
        "id": "rOerrcXxEvGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "0d3016c0-e6bb-482e-e55a-19a312021096"
      },
      "cell_type": "code",
      "source": [
        "# それぞれのカラムに ? が何個あるかカウント(確認)\n",
        "for col_name in auto_data.columns:\n",
        "    print(col_name,sum(auto_data[col_name].isin(['?'])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "symboling 0\n",
            "normalized-losses 41\n",
            "make 0\n",
            "fuel-type 0\n",
            "aspiration 0\n",
            "num-of-doors 2\n",
            "body-style 0\n",
            "drive-wheels 0\n",
            "engine-location 0\n",
            "wheel-base 0\n",
            "length 0\n",
            "width 0\n",
            "height 0\n",
            "curb-weight 0\n",
            "engine-type 0\n",
            "num-of-cylinders 0\n",
            "engine-size 0\n",
            "fuel-system 0\n",
            "bore 4\n",
            "stroke 4\n",
            "compression-ratio 0\n",
            "horsepower 2\n",
            "peak-rpm 2\n",
            "city-mpg 0\n",
            "highway-mpg 0\n",
            "price 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OiKDrhRmEvGR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "priceの他にもhorsepowerに?があるので、除外します。"
      ]
    },
    {
      "metadata": {
        "id": "cNEOe_aIEvGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub_auto_data = auto_data[[\"price\",\"horsepower\",\"width\",\"height\"]]\n",
        "sub_auto_data = sub_auto_data.replace('?', np.nan).dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7n_BmGwOEvGX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また、扱う変数の型が数値ではないため、数値に変換をするため、to_numericを使います。"
      ]
    },
    {
      "metadata": {
        "id": "9Cn70f-oEvGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "82313f6f-cbdf-4b8c-997d-7070bf2ffa56"
      },
      "cell_type": "code",
      "source": [
        "sub_auto_data = sub_auto_data.assign(price=pd.to_numeric(sub_auto_data.price))\n",
        "sub_auto_data = sub_auto_data.assign(horsepower=pd.to_numeric(sub_auto_data.horsepower))\n",
        "sub_auto_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13495</td>\n",
              "      <td>111</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16500</td>\n",
              "      <td>111</td>\n",
              "      <td>64.1</td>\n",
              "      <td>48.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16500</td>\n",
              "      <td>154</td>\n",
              "      <td>65.5</td>\n",
              "      <td>52.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13950</td>\n",
              "      <td>102</td>\n",
              "      <td>66.2</td>\n",
              "      <td>54.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17450</td>\n",
              "      <td>115</td>\n",
              "      <td>66.4</td>\n",
              "      <td>54.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   price  horsepower  width  height\n",
              "0  13495         111   64.1    48.8\n",
              "1  16500         111   64.1    48.8\n",
              "2  16500         154   65.5    52.4\n",
              "3  13950         102   66.2    54.3\n",
              "4  17450         115   66.4    54.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "ezfDp36eEvGe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、簡単ですが、各変数の相関行列を見てみましょう。priceは今回の目的変数なので、それ以外の3つの変数に注目をすると、widthとhorsepowerが若干相関係数が高めに出ています。なぜこのようなチェックをしているかというと、**多重共線性**という現象が生じる可能性があるからです。同じような（相関の強い）説明変数をモデルに投入しても、モデルの説明力が上がるわけではなく、むしろモデルが不安定になるという現象です。通常、同じような変数からは、代表とする変数のみモデルに使用します。（余談ですが、ネット上の投稿で、この多重共線性を説明する時に、「キャラかぶりは良くない」というたとえを使ってクライアントの前で説明することで理解を得ることが多かった、という投稿がありました。）"
      ]
    },
    {
      "metadata": {
        "id": "72ZZeaWyEvGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f05acc38-f429-4312-f528-2650beab837a"
      },
      "cell_type": "code",
      "source": [
        "sub_auto_data.corr()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.810533</td>\n",
              "      <td>0.753871</td>\n",
              "      <td>0.134990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horsepower</th>\n",
              "      <td>0.810533</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.615315</td>\n",
              "      <td>-0.087407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>width</th>\n",
              "      <td>0.753871</td>\n",
              "      <td>0.615315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.309223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height</th>\n",
              "      <td>0.134990</td>\n",
              "      <td>-0.087407</td>\n",
              "      <td>0.309223</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               price  horsepower     width    height\n",
              "price       1.000000    0.810533  0.753871  0.134990\n",
              "horsepower  0.810533    1.000000  0.615315 -0.087407\n",
              "width       0.753871    0.615315  1.000000  0.309223\n",
              "height      0.134990   -0.087407  0.309223  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "5kztzNtUEvGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは、早速、モデリングをしてみましょう。なお、ここでmodel_selectionのモジュールを使って、モデリングを構築する時に、学習データとテストデータに分けて、モデルスコアをチェックしています。簡単に言うと、モデルの汎化能力を確かめるためのアプローチで、作ったモデルをチェックするために、あらかじめテストデータを抜いておきます。詳しいことは13章以降に学びます。汎化能力に対して簡単に説明すると、機械学習のモデルは未知のデータに対して精度よく予測できることが重要になります。ですので、学習データに対する精度も大切ですが、テストデータに対する精度、つまり汎化性能を見ることが大切になります。訓練データに対する精度はいいが、テストデータに対する精度が低い時は、過学習(訓練データにだけfitするように学習)している可能性が高いので注意が必要です。また、random_stateを固定し再現性を持たせておくことは実務上は大事なので、random_state=0と設定しています（以後、基本的に固定します）。random_sateを固定しないと、毎実行のたびに数値が変わり、モデル間の精度の違いが乱数によって左右される可能性があり、モデル間の比較が正確にできなくなります。"
      ]
    },
    {
      "metadata": {
        "id": "Sm56qfhjEvGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "95c5b466-0513-4637-ddab-41d85cac8df3"
      },
      "cell_type": "code",
      "source": [
        "# データの分割（学習データとテストデータに分ける）\n",
        "# sklearnのバージョンによっては train_test_splitはsklearn.cross_validationにしか入ってない場合があります\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# モデル\n",
        "from sklearn import linear_model\n",
        "\n",
        "# モデルのインスタンス\n",
        "l_model = linear_model.LinearRegression()\n",
        " \n",
        "# 説明変数に \"price\" 以外を利用\n",
        "X = sub_auto_data.drop(\"price\", axis=1)\n",
        "\n",
        "# 目的変数\n",
        "Y = sub_auto_data[\"price\"]\n",
        "\n",
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5,random_state=0)\n",
        "\n",
        "# モデルのあてはめ\n",
        "clf = l_model.fit(X_train,y_train)\n",
        "print(\"train:\",clf.__class__.__name__ ,clf.score(X_train,y_train))\n",
        "print(\"test:\",clf.__class__.__name__ , clf.score(X_test,y_test))\n",
        " \n",
        "# 偏回帰係数\n",
        "print(pd.DataFrame({\"Name\":X.columns,\n",
        "                    \"Coefficients\":clf.coef_}).sort_values(by='Coefficients') )\n",
        " \n",
        "# 切片 \n",
        "print(clf.intercept_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: LinearRegression 0.7333575683901379\n",
            "test: LinearRegression 0.7370688738125762\n",
            "   Coefficients        Name\n",
            "0     81.651078  horsepower\n",
            "2    229.510077      height\n",
            "1   1829.174506       width\n",
            "-128409.0463033857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9sesh37wEvGq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "決定係数はtrain(学習データ)で73%、test(テストデータ)で73%という結果なので、モデルが過学習に陥ってはいないようです。"
      ]
    },
    {
      "metadata": {
        "id": "fN-Ao7n4EvGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以上が重回帰分析の使い方でしたが、以下で学ぶ決定木やSVMなども基本的に同じ流れで実装していきます。この講座では個々のアルゴリズムについての詳細は記載せず、あくまで使うことを目的としていますので、まずは以下の流れでモデリングの検証をすることをおさえてください。"
      ]
    },
    {
      "metadata": {
        "id": "LWy5tmk6EvGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- 該当モジュールの読み込みとモデルの呼び出し：linear_model.LinearRegression()\n",
        "- データを説明変数と目的変数に分ける：XとY\n",
        "- 訓練データとテストデータに分ける：train_test_split(X, Y, test_size=0.5,random_state=0)\n",
        "- 訓練データによるあてはめ（係数推定）：fit(X_train,y_train)\n",
        "- 上記で構築したモデルを、テストデータで確かめる：score(X_test,y_test)"
      ]
    },
    {
      "metadata": {
        "id": "RUVzhMfREvGu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、他のモジュールですが、statsmodelsも重回帰分析等が計算できます。統計フリーソフトウェアのR言語を使い慣れている方は、以下のような表示を見慣れていると思いますので、参考に記載します。（なお、以下は訓練データとテストデータには分けず、モデルをそのまま適応しています。）"
      ]
    },
    {
      "metadata": {
        "id": "BOX__5oBEvGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "32fe1170-bdf5-4e39-ad88-60d300927204"
      },
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OB9HbQTPEvGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = smf.ols('price ~ horsepower+width+height', data=sub_auto_data).fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hom9n5W9EvG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CrEe-JcgEvG8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "heightのp-valueが有意水準を5%とした場合、若干上回っていますが、そこまで高い数値ではないので、その場の状況において判断しましょう。p値（p-value）が小さいと、その説明変数は確率論的にモデルの説明力に寄与していると言えますが、決定係数やデータ自体に対する知見を持って総合的に判断することが重要です。"
      ]
    },
    {
      "metadata": {
        "id": "tMM17YfiEvG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、ここではモデリングする際に変数をhorsepower、width、heightに決めて実装しました。この時に、「なんでこれらの変数なのか」と思われるのは自然で、実際には変数を選択するための方法もいくつかあります。具体的には、**変数増加法（前進的選択法）**、**変数減少法（後退的選択法）**、**ステップワイズ法**など、また選択するための規準（RMSE（Root Mean Squared Error）、赤池情報量規準（AIC）、ベイズ情報量規準（BIC）など）があります。\n",
        "\n",
        "もちろん、これらも絶対的にこの方法が有効という基準はなく、データの予測精度だったり、ビジネス的な理由で、ある変数を入れる必要があったりします。上の方法については詳細はここでは述べませんが、興味のある方は調べてみてください。"
      ]
    },
    {
      "metadata": {
        "id": "0EkBCOf0EvG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**[やってみよう]**\n",
        "\n",
        ">上の変数選択法や情報量規準について調べてみましょう。どのような方法で、それぞれどんな特徴がありますか。"
      ]
    },
    {
      "metadata": {
        "id": "tcc45VnlEvHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 1>\n",
        "上記のデータを使って、目的変数は同じpriceで、説明変数にlengthとengine-sizeを使って、重回帰分析をしてみましょう。ただし、学習データとテストデータが半分になるように分けてモデリングして、テストデータでスコアを求めてください。なお、学習データとテストデータに分けるメソッドのrandom_stateは0に設定して実施してください。"
      ]
    },
    {
      "metadata": {
        "id": "71YANdPWe-8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auto_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZggif9jhzAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auto_data = auto_data[[\"price\",\"length\",\"engine-size\"]]\n",
        "auto_data = auto_data.replace('?', np.nan).dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0BVnaGPxT04O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# モデルのインスタンス\n",
        "l_model2 = linear_model.LinearRegression()\n",
        "\n",
        "auto_data = auto_data.assign(price=pd.to_numeric(auto_data.price))\n",
        "auto_data = auto_data.assign(length=pd.to_numeric(auto_data.length))\n",
        "#auto_data = auto_data.assign(engine-size=pd.to_numeric(auto_data.engine-size))\n",
        " \n",
        "# 説明変数\n",
        "X = auto_data[[\"length\",\"engine-size\"]]\n",
        "\n",
        "# 目的変数\n",
        "Y = auto_data[\"price\"]\n",
        "\n",
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5,random_state=0)\n",
        "\n",
        "# モデルのあてはめ\n",
        "clf2 = l_model2.fit(X_train,y_train)\n",
        "print(\"train:\",clf2.__class__.__name__ ,clf2.score(X_train,y_train))\n",
        "print(\"test:\",clf2.__class__.__name__ , clf2.score(X_test,y_test))\n",
        " \n",
        "# 偏回帰係数\n",
        "print(pd.DataFrame({\"Name\":X.columns,\n",
        "                    \"Coefficients\":clf2.coef_}).sort_values(by='Coefficients') )\n",
        " \n",
        "# 切片 \n",
        "print(clf2.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ivJLwlVEvHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 2>\n",
        "上記のデータを使って、目的変数は同じpriceで、上記とは別の説明変数を使って、重回帰分析をしてみましょう。ただし、学習データとテストデータが半分になるように分けてモデリングして、テストデータでスコアを求めてください。なお、学習データとテストデータ分けるメソッドのrandom_stateは0に設定して実施してください。モデルの結果がどのように変わったでしょうか。また、その原因を考察してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "7QPG6UV_VQ-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6YoiCO4EvHG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.3 ロジスティック回帰分析\n",
        "ゴール：ロジスティック回帰分析、オッズ比"
      ]
    },
    {
      "metadata": {
        "id": "BWJyr2dREvHI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "先ほどの重回帰分析は目的変数が連続数値で、その数値の予測を実施しました。次は、予測したい変数が連続数値ではなく、例えば、ある商品を買うか買わないか、ある会社が倒産するかしないか等を予測したいケースについて考えてみます。このようにあるグループに属するかどうかというのを確率を計算するアプローチが**ロジスティック回帰分析**です。回帰という名前がついていますが、分類の問題を考えるので注意しましょう。（また、2分類だけではなく3分類や5分類などする時も使えます。）目的変数が連続値の時と違い、分類の際には以下の目的関数が最小になるように学習します。この目的関数を**交差エントロピー誤差**と言います。"
      ]
    },
    {
      "metadata": {
        "id": "GR_K7KMBEvHK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        "-\\sum^n_{i=1}[y_ilog(f(x_i))+(1-y_i)log(1-f(x_i))]\n",
        "\\end{eqnarray}"
      ]
    },
    {
      "metadata": {
        "id": "QokMpV0CEvHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次の個人に関するデータ（年齢や性別、職業など）で、その人の収入が50K（5万ドル）を超えるかどうかを予測したいとして、モデリングしてみましょう。まずは、以下のようにデータを取得し、カラム名を設定します。"
      ]
    },
    {
      "metadata": {
        "id": "L7McDWgwEvHL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの取得\n",
        "import requests\n",
        "from io import StringIO\n",
        "import io\n",
        "\n",
        "# url \n",
        "adult_data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "s=requests.get(adult_data_url).content\n",
        "adult_data = pd.read_csv(io.StringIO(s.decode('utf-8')),header=None)\n",
        "adult_data.columns =[\"age\",\"workclass\",\"fnlwgt\",\"education\"\n",
        "                     ,\"education-num\",\"marital-status\",\"occupation\"\n",
        "                     ,\"relationship\",\"race\",\"sex\",\"capital-gain\"\n",
        "                     ,\"capital-loss\",\"hours-per-week\",\"native-country\",\"flg-50K\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iax1uDTPEvHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "いつもと同じようにどんなデータがあるか眺めてみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "9zY-sIJ8EvHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "8b22223b-4f3d-4695-9f9f-7865188a216d"
      },
      "cell_type": "code",
      "source": [
        "adult_data.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            "age               32561 non-null int64\n",
            "workclass         32561 non-null object\n",
            "fnlwgt            32561 non-null int64\n",
            "education         32561 non-null object\n",
            "education-num     32561 non-null int64\n",
            "marital-status    32561 non-null object\n",
            "occupation        32561 non-null object\n",
            "relationship      32561 non-null object\n",
            "race              32561 non-null object\n",
            "sex               32561 non-null object\n",
            "capital-gain      32561 non-null int64\n",
            "capital-loss      32561 non-null int64\n",
            "hours-per-week    32561 non-null int64\n",
            "native-country    32561 non-null object\n",
            "flg-50K           32561 non-null object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kAAKy8cB2gy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4ffab1a6-3512-47f5-8095-2816dfc9b0da"
      },
      "cell_type": "code",
      "source": [
        "adult_data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>flg-50K</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  fnlwgt   education  education-num  \\\n",
              "0   39          State-gov   77516   Bachelors             13   \n",
              "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
              "2   38            Private  215646     HS-grad              9   \n",
              "3   53            Private  234721        11th              7   \n",
              "4   28            Private  338409   Bachelors             13   \n",
              "\n",
              "        marital-status          occupation    relationship    race      sex  \\\n",
              "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
              "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
              "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
              "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
              "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
              "\n",
              "   capital-gain  capital-loss  hours-per-week  native-country flg-50K  \n",
              "0          2174             0              40   United-States   <=50K  \n",
              "1             0             0              13   United-States   <=50K  \n",
              "2             0             0              40   United-States   <=50K  \n",
              "3             0             0              40   United-States   <=50K  \n",
              "4             0             0              40            Cuba   <=50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "3FPe3jC6EvHT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、同じようにデータを確保しておくために、csvファイルとして保存しておきましょう。"
      ]
    },
    {
      "metadata": {
        "id": "uNW0mW88EvHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adult_data.to_csv('adult_data.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-OfyMY9BEvHW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "目的変数は「flg-50K」になります。データとして <=50Kと >50Kがあり、このままでは扱いにくいので、フラグを立てることにしましょう。"
      ]
    },
    {
      "metadata": {
        "id": "XCopD1qJEvHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "38b268b6-7c98-4f57-e511-0fe61e6b09e4"
      },
      "cell_type": "code",
      "source": [
        "adult_data.groupby(\"flg-50K\").size()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "flg-50K\n",
              " <=50K    24720\n",
              " >50K      7841\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "9Q8m50MZEvHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "記号の「>50K」を1として、それ以外は0とフラグ立てをします。フラグ立てのためには、lambda関数を使いましょう。"
      ]
    },
    {
      "metadata": {
        "id": "hwsMxM2nEvHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 目的変数：flg立てをする\n",
        "adult_data[\"fin_flg\"] = adult_data[\"flg-50K\"].map(lambda x: 1 if x ==' >50K' else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OO2i1-3ZEvHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "念のため上の集計結果と同じであることをチェックしています。"
      ]
    },
    {
      "metadata": {
        "id": "CN2_1ShREvHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "814cf646-e13f-4d75-f2bc-4f2e7c47529c"
      },
      "cell_type": "code",
      "source": [
        "adult_data.groupby(\"fin_flg\").size()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fin_flg\n",
              "0    24720\n",
              "1     7841\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "kKdZQ9h9EvHj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "いよいよロジスティク回帰分析のモデリングです。説明変数としては、\"age\",\"fnlwgt\",\"education-num\",\"capital-gain\",\"capital-loss\"を使うことにしましょう。ロジスティック回帰はLogisticRegressionを使います。"
      ]
    },
    {
      "metadata": {
        "id": "s7nxvTG5EvHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "62842af2-ca0c-4d5c-d1fb-3c9e86b2a3fd"
      },
      "cell_type": "code",
      "source": [
        "# ロジスティック回帰\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 説明変数と目的変数\n",
        "X = adult_data[[\"age\",\"fnlwgt\",\"education-num\",\"capital-gain\",\"capital-loss\"]]\n",
        "Y = adult_data['fin_flg']\n",
        "\n",
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)\n",
        "\n",
        "# ロジスティック回帰のインスタンス\n",
        "model = LogisticRegression()\n",
        "\n",
        "# モデルのあてはめ\n",
        "clf = model.fit(X_train,y_train)\n",
        "\n",
        "print(\"train result:\",clf.score(X_train,y_train))\n",
        "print(\"test result:\" , clf.score(X_test,y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train result: 0.7973791973791974\n",
            "test result: 0.7949883306719077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i32LCN4pEvHn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記の結果から、訓練データとテストデータともに約79%の正解率であることがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "JZvnH-63EvHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さて、ここで予測精度を上げるためのアプローチの1つであるスケーリングについて考えることにします。上の説明変数を見ていただくとわかる通り、それぞれ単位や大きさが異なっており、このままですと大きな変数に引っ張られて、小さな変数の影響度合いが見えにくくなってしまいます。\n",
        "\n",
        "そこで、特徴量(ここではX)の標準化を実施してみます。以下の結果を見てみると、スコア（正解率）が上がっています。標準化とは、スケーリングの一種で、それぞれの変数のスケールを合わせます。このように特徴量の尺度を揃えることで、機械学習のアルゴリズムがうまく動作します。ただし、後から述べる決定木等は単なる大小比較のため、変わりません。"
      ]
    },
    {
      "metadata": {
        "id": "aH0FPtBIEvHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2fc3bc6d-eefc-4ef2-aedd-c88de449ac5b"
      },
      "cell_type": "code",
      "source": [
        "# ロジスティック回帰\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 標準化のためのモジュール\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 説明変数と目的変数\n",
        "X = adult_data[[\"age\",\"fnlwgt\",\"education-num\",\"capital-gain\",\"capital-loss\"]]\n",
        "Y = adult_data['fin_flg']\n",
        "\n",
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)\n",
        "\n",
        "# ロジスティック回帰\n",
        "model = LogisticRegression()\n",
        "\n",
        "# 標準化\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "clf = model.fit(X_train_std,y_train)\n",
        "print(\"train:\",clf.score(X_train_std,y_train))\n",
        "print(\"test:\", clf.score(X_test_std,y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 0.8104832104832105\n",
            "test: 0.8099742046431643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gSJGA6RbEvHz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、訓練データで作成したモデルにおける各変数の係数を見るには、coef_を使います。"
      ]
    },
    {
      "metadata": {
        "id": "EekPz0I6EvH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40e58a8b-0c4a-44a5-93d9-a5489b871491"
      },
      "cell_type": "code",
      "source": [
        "clf.coef_"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.531, 0.03 , 0.857, 2.431, 0.284]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "jvIb3zVBEvH7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また、それぞれのオッズ比は以下のように算出できます。"
      ]
    },
    {
      "metadata": {
        "id": "e7-HRvOUEvH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48d8446d-a66d-4bf9-f22d-2f28cd517f31"
      },
      "cell_type": "code",
      "source": [
        "np.exp(clf.coef_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.701,  1.031,  2.355, 11.376,  1.328]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "OP5XdR9AEvIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 1>\n",
        "sklearn.datasetsのload_breast_cancerを読み込んで、目的変数をcancer.targetとして、cancer.dataを説明変数にロジスティック回帰で予測モデルを構築してください。この時、訓練データとテストデータに分けるtrain_test_split（random_state=0）を使って、テストデータにおけるスコアを求めてください。"
      ]
    },
    {
      "metadata": {
        "id": "me2HbCNcnKd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# breast_cancerデータ読み込み\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4XTxYLq1iNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = cancer.data\n",
        "Y = cancer.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5MnDiTw1ng-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ロジスティック回帰\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)\n",
        "\n",
        "# ロジスティック回帰のインスタンス\n",
        "model = LogisticRegression()\n",
        "\n",
        "# モデルのあてはめ\n",
        "clf = model.fit(X_train,y_train)\n",
        "\n",
        "print(\"train result:\",clf.score(X_train,y_train))\n",
        "print(\"test result:\" , clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOmyzHY7EvII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 2>\n",
        "上記と同じ設定・データに対して、特徴量を標準化して、モデリングしてみてください。その上で、上記の結果と比較してください。"
      ]
    },
    {
      "metadata": {
        "id": "9hOGqaqB5CaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,random_state=0)\n",
        "\n",
        "# ロジスティック回帰\n",
        "model = LogisticRegression()\n",
        "\n",
        "# 標準化\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "clf = model.fit(X_train_std,y_train)\n",
        "print(\"train:\",clf.score(X_train_std,y_train))\n",
        "print(\"test:\", clf.score(X_test_std,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvdLzCMvEvIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.4 正則化、ラッソ回帰、リッジ回帰\n",
        "ゴール：正則化、ラッソ回帰、リッジ回帰"
      ]
    },
    {
      "metadata": {
        "id": "Y-Mpq7xPEvIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "複雑なモデルを作れば、今持っているデータにマッチするモデルはできるかもしれません。しかし、重要なのはモデルの汎化能力です。ここでは、モデルを複雑にしたとき、今持っているデータだけでなく、未知のデータをうまく予測できることを考えます。\n",
        "\n",
        "回帰分析で最小2乗法で誤差を考えましたが、そこにこのモデルの複雑さを表す式を加えます。この場合、複雑なモデルであればあるほどペナルティが与えられ、これを**正則化**といいます。またその正則化項は以下のようになり、q=1の時はラッソ回帰、q=2の時はリッジ回帰と言います。（M：変数の数、w：重み付け（係数）、λ：正則化パラメータ）"
      ]
    },
    {
      "metadata": {
        "id": "gfsIvTcFEvIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        "\\lambda\\sum^M_{j=1} |w_{j}|^q\n",
        "\\end{eqnarray}"
      ]
    },
    {
      "metadata": {
        "id": "0mRWsJ5hEvIO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "変数の数Mを増やせば増やすほど、重みも増やせば増やすほど上記の式も大きくなり、それがペナルティとして考慮されるのがわかると思います。\n",
        "\n",
        "モデルは以下の目的関数が最小になるように学習します。この式を最小にするためにはペナルティ項を小さくすることが必要になるので、モデルの複雑さを抑えることにつながります。"
      ]
    },
    {
      "metadata": {
        "id": "GmtJs2zeEvIP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        "\\sum^n_{i=1}(y_i-f(x_i))^2+\\lambda\\sum^M_{j=1} |w_{j}|^q\n",
        "\\end{eqnarray}"
      ]
    },
    {
      "metadata": {
        "id": "_gwx2gh1EvIQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "重回帰、ロジスティック回帰が、投入する説明変数の数を分析者側で調整することによってモデルの複雑性を調整するのに対し、ラッソ回帰、リッジ回帰はパラメータ自体の大きさをモデル自身が小さく抑えることによってモデルの複雑性を調整するアプローチと考えることができます。トレーニングスコアとテストスコアに乖離がある場合、モデルをシンプルにすることで改善されることがあります。ちなみに、分類に対しても正規化項を加えることができます(ですが、分類問題での正規化項付きのモデルには特に名前がありません)。"
      ]
    },
    {
      "metadata": {
        "id": "X2q_2UXiEvIR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここでは、先ほど重回帰分析で使った自動車価格のデータを使って、普通の線形回帰とリッジ回帰の結果の差を見てみます。モジュールはlinear_modelで、リッジ回帰はRidgeを使います。(練習問題でLassoを使います。)"
      ]
    },
    {
      "metadata": {
        "id": "-C-Cy43CEvIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ad0dc3be-d4b3-4531-95d0-e2c186eb62e4"
      },
      "cell_type": "code",
      "source": [
        "# データの分割（学習データとテストデータ分ける）\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# モデル\n",
        "from sklearn import linear_model\n",
        " \n",
        "# 説明変数に \"price\" 以外を利用\n",
        "X = sub_auto_data.drop(\"price\", axis=1)\n",
        "\n",
        "# 目的変数\n",
        "Y = sub_auto_data[\"price\"]\n",
        "\n",
        "# 普通の線形回帰\n",
        "model_linear = linear_model.LinearRegression()\n",
        "\n",
        "# リッジ回帰\n",
        "model_ridge = linear_model.Ridge()\n",
        "\n",
        "# 学習データとテストデータ分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5,random_state=0)\n",
        "\n",
        "\n",
        "# 普通の線形回帰とリッジ回帰でそれぞれスコアを算出\n",
        "for model in [model_linear,model_ridge]:\n",
        "    clf = model.fit(X_train,y_train)\n",
        "    print(\"train:\",clf.__class__.__name__ ,clf.score(X_train,y_train))\n",
        "    print(\"test:\",clf.__class__.__name__ , clf.score(X_test,y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: LinearRegression 0.7333575683901379\n",
            "test: LinearRegression 0.7370688738125762\n",
            "train: Ridge 0.7333547383511865\n",
            "test: Ridge 0.737767688500683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N4Z-P80kEvIV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上の結果から、訓練データにおいて、普通の線形回帰のスコアが若干良くなっていますが、テストデータにおいてはリッジ回帰が若干良くなっているのがわかり、正則化項を加えることでモデルの汎化性が高まったことがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "oaSulHuoEvIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 1>\n",
        "上記と同じ設定・データに対して、ラッソ回帰を実施してください。Lassoを使います。なお、パラメータ設定できますので、調べてみてください。"
      ]
    },
    {
      "metadata": {
        "id": "RCAimIHO7NzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの分割（学習データとテストデータ分ける）\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# モデル\n",
        "from sklearn import linear_model\n",
        " \n",
        "# 説明変数に \"price\" 以外を利用\n",
        "X = sub_auto_data.drop(\"price\", axis=1)\n",
        "\n",
        "# 目的変数\n",
        "Y = sub_auto_data[\"price\"]\n",
        "\n",
        "# 普通の線形回帰\n",
        "model_linear = linear_model.LinearRegression()\n",
        "\n",
        "# ラッソ回帰\n",
        "model_lasso = linear_model.Lasso()\n",
        "\n",
        "# 学習データとテストデータ分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5,random_state=0)\n",
        "\n",
        "\n",
        "# 普通の線形回帰とラッソ回帰でそれぞれスコアを算出\n",
        "for model in [model_linear,model_lasso]:\n",
        "    clf = model.fit(X_train,y_train)\n",
        "    print(\"train:\",clf.__class__.__name__ ,clf.score(X_train,y_train))\n",
        "    print(\"test:\",clf.__class__.__name__ , clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YFs19BiPEvIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.5 決定木\n",
        "ゴール：決定木、分類木、回帰木、エントロピー、情報利得、ジニ不純度、分類誤差"
      ]
    },
    {
      "metadata": {
        "id": "MI8ZtrSAEvIX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここで扱っていくデータはキノコのデータです。キノコには食用キノコとそうでないもの（毒キノコ）がありますが、今回の目的は、与えられたキノコが食用かどうかを見分けることです。仮に、無人島などにおかれてキノコしかないときには、命に関わる切実な問題になりますので、必死に考えていきましょう。\n",
        "\n",
        "さて、キノコの属性として色々なデータがあります。カサの形、匂い、ヒダの大きさなどです。今回扱うデータには、それらの属性データが20種類以上もあります。この属性データから、例えば、かさの形が円錐形かそうでないかで、ヒダの色が黒色なのか赤色なのか、その大きさは大きいのか小さいのか、というように条件分岐をしていき、最終的にそのキノコが毒かそうでないかを見分けます。"
      ]
    },
    {
      "metadata": {
        "id": "F_G2qq07EvIY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](http://www.prairiemushrooms.com/files/styles/banner_image_view_masthead_block/public/banner/image/Banner_Image_-_Various_Mushrooms.jpg?itok=Ka6WfrJa)"
      ]
    },
    {
      "metadata": {
        "id": "1_SIgFPaEvIZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL:http://www.prairiemushrooms.com/files/styles/banner_image_view_masthead_block/public/banner/image/Banner_Image_-_Various_Mushrooms.jpg?itok=Ka6WfrJa"
      ]
    },
    {
      "metadata": {
        "id": "sj3NWPamEvIZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "このように、ある目的（毒キノコかそうでないか、ある商品を購買するかどうかなど）に到達するために、データの各属性の条件分岐をして、グループに分けていく方法を**決定木**といいます。目的に辿りつくのにいろいろなルートがあり、それがツリー状になっているために決定木といいます。さらに、この決定木は、目的となる変数がカテゴリー変数の場合は**分類木**といいますが、連続値である場合も使うことができて、それを**回帰木**といいます。"
      ]
    },
    {
      "metadata": {
        "id": "XFHseX4pEvIa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL：http://blogs.teradata.com/international/ja/hhg14/"
      ]
    },
    {
      "metadata": {
        "id": "P8XH9DfrEvIb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ビジネスの現場としては、マーケティングの分野で、ある商品を購買をする人がどのような属性を持っているのか(\n",
        "女性なのか男性なのか、年収は平均以上かそうでないか、別の商品を買っているかどうかなど)、いろいろと条件分岐ができ、**セグメンテーション**のアプローチにも使われたります。"
      ]
    },
    {
      "metadata": {
        "id": "F0s100lGEvIc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "それでは、早速このキノコデータを読み込んでみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "kIc_CC5lEvIe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# きのこデータの取得\n",
        "import requests, zipfile\n",
        "from io import StringIO\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# url \n",
        "mush_data_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
        "s=requests.get(mush_data_url).content\n",
        "\n",
        "mush_data = pd.read_csv(io.StringIO(s.decode('utf-8')),header=None)\n",
        "\n",
        "mush_data.columns =[\"classes\",\"cap_shape\",\"cap_surface\",\"cap_color\",\"odor\",\"bruises\",\n",
        "                    \"gill_attachment\",\"gill_spacing\",\"gill_size\",\"gill_color\",\"stalk_shape\",\n",
        "                   \"stalk_root\",\"stalk_surface_above_ring\",\"stalk_surface_below_ring\",\n",
        "                    \"stalk_color_above_ring\",\"stalk_color_below_ring\",\"veil_type\",\"veil_color\",\n",
        "                    \"ring_number\",\"ring_type\",\"spore_print_color\",\"population\",\"habitat\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOPXVdZSEvIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "いつもと同じように、headでデータを確認します。目的変数は、classesです。これが、pの場合は毒、eの場合は食用です。1つレコード（行）が1つのキノコの情報で、属性（cap_shapeやcap_surfaceなど）がそれぞれ付いています。例えば、1つ目の行のキノコは、classesがpなので毒キノコで、cap_shape（カサの形）はx（convex）になっています。なお、属性の詳しい情報は以下で記載します。"
      ]
    },
    {
      "metadata": {
        "id": "mJOIyS8sEvIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "b38bfcf7-8127-4ede-e5b6-d4060b82090f"
      },
      "cell_type": "code",
      "source": [
        "mush_data.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classes</th>\n",
              "      <th>cap_shape</th>\n",
              "      <th>cap_surface</th>\n",
              "      <th>cap_color</th>\n",
              "      <th>odor</th>\n",
              "      <th>bruises</th>\n",
              "      <th>gill_attachment</th>\n",
              "      <th>gill_spacing</th>\n",
              "      <th>gill_size</th>\n",
              "      <th>gill_color</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk_surface_below_ring</th>\n",
              "      <th>stalk_color_above_ring</th>\n",
              "      <th>stalk_color_below_ring</th>\n",
              "      <th>veil_type</th>\n",
              "      <th>veil_color</th>\n",
              "      <th>ring_number</th>\n",
              "      <th>ring_type</th>\n",
              "      <th>spore_print_color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e</td>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  classes cap_shape cap_surface cap_color odor bruises gill_attachment  \\\n",
              "0       p         x           s         n    t       p               f   \n",
              "1       e         x           s         y    t       a               f   \n",
              "2       e         b           s         w    t       l               f   \n",
              "3       p         x           y         w    t       p               f   \n",
              "4       e         x           s         g    f       n               f   \n",
              "\n",
              "  gill_spacing gill_size gill_color   ...   stalk_surface_below_ring  \\\n",
              "0            c         n          k   ...                          s   \n",
              "1            c         b          k   ...                          s   \n",
              "2            c         b          n   ...                          s   \n",
              "3            c         n          n   ...                          s   \n",
              "4            w         b          k   ...                          s   \n",
              "\n",
              "  stalk_color_above_ring stalk_color_below_ring veil_type veil_color  \\\n",
              "0                      w                      w         p          w   \n",
              "1                      w                      w         p          w   \n",
              "2                      w                      w         p          w   \n",
              "3                      w                      w         p          w   \n",
              "4                      w                      w         p          w   \n",
              "\n",
              "  ring_number ring_type spore_print_color population habitat  \n",
              "0           o         p                 k          s       u  \n",
              "1           o         p                 n          n       g  \n",
              "2           o         p                 n          n       m  \n",
              "3           o         p                 k          s       u  \n",
              "4           o         e                 n          a       g  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZauW9PQEvIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "また、データを確保しておくために、csvファイルとして保存しておきましょう。"
      ]
    },
    {
      "metadata": {
        "id": "7_UQZyukEvIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mush_data.to_csv('mush_data.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52K2t0FgEvIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "いつもと同じようにデータがいくつかあるか、欠損があるか見てみます。レコード数は8124で、全てのnon-nullとなっているので、欠けているデータはないようです。"
      ]
    },
    {
      "metadata": {
        "id": "d99RVePwEvIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "6b630055-526f-45e8-90e4-48a6f9587f5d"
      },
      "cell_type": "code",
      "source": [
        "mush_data.info()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8124 entries, 0 to 8123\n",
            "Data columns (total 23 columns):\n",
            "classes                     8124 non-null object\n",
            "cap_shape                   8124 non-null object\n",
            "cap_surface                 8124 non-null object\n",
            "cap_color                   8124 non-null object\n",
            "odor                        8124 non-null object\n",
            "bruises                     8124 non-null object\n",
            "gill_attachment             8124 non-null object\n",
            "gill_spacing                8124 non-null object\n",
            "gill_size                   8124 non-null object\n",
            "gill_color                  8124 non-null object\n",
            "stalk_shape                 8124 non-null object\n",
            "stalk_root                  8124 non-null object\n",
            "stalk_surface_above_ring    8124 non-null object\n",
            "stalk_surface_below_ring    8124 non-null object\n",
            "stalk_color_above_ring      8124 non-null object\n",
            "stalk_color_below_ring      8124 non-null object\n",
            "veil_type                   8124 non-null object\n",
            "veil_color                  8124 non-null object\n",
            "ring_number                 8124 non-null object\n",
            "ring_type                   8124 non-null object\n",
            "spore_print_color           8124 non-null object\n",
            "population                  8124 non-null object\n",
            "habitat                     8124 non-null object\n",
            "dtypes: object(23)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i6HvUg7oEvIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以下は参考ですが、それぞれの属性に関する解説です。"
      ]
    },
    {
      "metadata": {
        "id": "GIOOy7t8EvIz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "0. classes: edible=e, poisonous=p\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s \n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s \n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y \n",
        "4. bruises?: bruises=t,no=f \n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s \n",
        "8. gill-attachment: attached=a,descending=d,free=f,notched=n \n",
        "7. gill-spacing: close=c,crowded=w,distant=d \n",
        "8. gill-size: broad=b,narrow=n \n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y \n",
        "10. stalk-shape: enlarging=e,tapering=t \n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=? \n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s \n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y \n",
        "18. veil-type: partial=p,universal=u \n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y \n",
        "18. ring-number: none=n,one=o,two=t \n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z \n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y \n",
        "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y \n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods="
      ]
    },
    {
      "metadata": {
        "id": "c9iMmu2_EvI0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "説明変数となる候補はた20以上ありますが、今回はこの中からいくつかピックアップします。ただし、上で見たようにデータは数値ではなく、カテゴリーとしてデータを持っているので、そのまま使うことはできません。cap-shapeはbellだったらb、conicalだったらcというように、数値データではありません。このカテゴリー変数をモデリングに使うために、ダミー変数として置換して使うことにしましょう。\n",
        "\n",
        "今扱っているデータは変数が多く分かりにくいので、ダミー変数に置換するというのがどういうことなのか、簡単な例で考えます。例えば、データとして性別の属性データがあったとして、maleかfemaleのデータが入っているとします。現在2種類のデータがあるので性別の列をmale列とfemale列の2列に分けて考えることにします。データとしてmaleがあった場合はmale列に1、female列に0をダミー変数として扱うことができます。逆に、データとしてfemaleがあった場合はmale列に0、female列に1になります。これがダミー変数に置換するということです。\n",
        "\n",
        "以下では、gill_color、gill_attachment、odor、cap_colorをダミー特徴量として変換しています。"
      ]
    },
    {
      "metadata": {
        "id": "L4a0YFb7EvI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 参考（カテゴリー変数をダミー特徴量として変換する方法）\n",
        "mush_data_dummy = pd.get_dummies(mush_data[['gill_color','gill_attachment','odor','cap_color']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIAuPUCAEvI5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "変換後のデータを以下に示します。例えば、gill_color_kに1が立っていたら、gill_colorがkになっていることを意味します。ダミー変数は、このようにカテゴリー変数をフラグ化したいときに設定します。"
      ]
    },
    {
      "metadata": {
        "id": "I8FPjaFgEvI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "ac413ebc-f58c-411d-92bd-75b55469c873"
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gill_color_b</th>\n",
              "      <th>gill_color_e</th>\n",
              "      <th>gill_color_g</th>\n",
              "      <th>gill_color_h</th>\n",
              "      <th>gill_color_k</th>\n",
              "      <th>gill_color_n</th>\n",
              "      <th>gill_color_o</th>\n",
              "      <th>gill_color_p</th>\n",
              "      <th>gill_color_r</th>\n",
              "      <th>gill_color_u</th>\n",
              "      <th>...</th>\n",
              "      <th>cap_color_b</th>\n",
              "      <th>cap_color_c</th>\n",
              "      <th>cap_color_e</th>\n",
              "      <th>cap_color_g</th>\n",
              "      <th>cap_color_n</th>\n",
              "      <th>cap_color_p</th>\n",
              "      <th>cap_color_r</th>\n",
              "      <th>cap_color_u</th>\n",
              "      <th>cap_color_w</th>\n",
              "      <th>cap_color_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   gill_color_b  gill_color_e  gill_color_g  gill_color_h  gill_color_k  \\\n",
              "0             0             0             0             0             1   \n",
              "1             0             0             0             0             1   \n",
              "2             0             0             0             0             0   \n",
              "3             0             0             0             0             0   \n",
              "4             0             0             0             0             1   \n",
              "\n",
              "   gill_color_n  gill_color_o  gill_color_p  gill_color_r  gill_color_u  \\\n",
              "0             0             0             0             0             0   \n",
              "1             0             0             0             0             0   \n",
              "2             1             0             0             0             0   \n",
              "3             1             0             0             0             0   \n",
              "4             0             0             0             0             0   \n",
              "\n",
              "      ...       cap_color_b  cap_color_c  cap_color_e  cap_color_g  \\\n",
              "0     ...                 0            0            0            0   \n",
              "1     ...                 0            0            0            0   \n",
              "2     ...                 0            0            0            0   \n",
              "3     ...                 0            0            0            0   \n",
              "4     ...                 0            0            0            1   \n",
              "\n",
              "   cap_color_n  cap_color_p  cap_color_r  cap_color_u  cap_color_w  \\\n",
              "0            1            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            1   \n",
              "3            0            0            0            0            1   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   cap_color_y  \n",
              "0            0  \n",
              "1            1  \n",
              "2            0  \n",
              "3            0  \n",
              "4            0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "HXjNpHeUEvI_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に、今回の目的であるキノコか毒かどうかのフラグ立てをして、新しい変数（目的変数flg）をデータの列として追加しています。なお、map関数とlambda関数を使って処理しています。やっている処理は、データの要素（セル）のclasses変数がpの場合は1、そうでない場合は0として（lambda関数の部分）、新しい変数flgとして追加しています。そして、map関数を使うことでその処理を全ての要素（セル）に適応させています。"
      ]
    },
    {
      "metadata": {
        "id": "ENWmi_P-EvJB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 目的変数：flg立てをする\n",
        "mush_data_dummy[\"flg\"] = mush_data[\"classes\"].map(lambda x: 1 if x =='p' else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GSyghGOUEvJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "目的変数が定まり、適切な加工処理を施しましたので、早速このデータを使って決定木を使ってみることにしましょう。決定木は、上記で述べたように、ある条件を満たすかどうかで場合分けをしていき、最終的に各グループの純度が上がる（毒キノコかそうでないかをよりうまく分けることができる）ように計算していきます。"
      ]
    },
    {
      "metadata": {
        "id": "7Mwfk0eDEvJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここで、この条件分岐ついて、具体的に考えてみることにしましょう。まずは、cap_colorがcであるかそうでないかのTURE(1) or FLASE(0)で分けることにして、その時にそれぞれ毒キノコがどれくらいいるのかクロス集計してみます。次の表は、行がcap_colorがcであるか(1)、そうでないか(0)、列が毒フラグflgが立っているか(1)、そうでないか(0)のクロス集計になっています。なお、pandasの復習ですが、unstack()を使って、表のように見せています。"
      ]
    },
    {
      "metadata": {
        "id": "3H44XZpGBBXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "468fdccd-6bd8-44e4-93a1-721514e487b9"
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.groupby([\"cap_color_c\", \"flg\"])[\"flg\"].count()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cap_color_c  flg\n",
              "0            0      4176\n",
              "             1      3904\n",
              "1            0        32\n",
              "             1        12\n",
              "Name: flg, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "zcvS2ITcEvJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "780ba091-557b-49a2-a9e0-053e74d337f7"
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.groupby([\"cap_color_c\", \"flg\"])[\"flg\"].count().unstack()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>flg</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cap_color_c</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4176</td>\n",
              "      <td>3904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "flg             0     1\n",
              "cap_color_c            \n",
              "0            4176  3904\n",
              "1              32    12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "P_ds7sYEEvJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記の表を見てみると、cap_colorがc(1)であれば毒(1)の数が12個で毒でない(0)数が32個になります。一方、cap_colorがcでなければ（0）、毒(1)の数が3904個で毒でない(0)数が4176個になります。この結果を見てみると、cap_colorがcであるかそうでないかの情報は、毒キノコを見分けるのに、あまり役に立たなそうです。なぜならどちらを選んでも、どちらも毒キノコが一定の割合で含まれているからです。"
      ]
    },
    {
      "metadata": {
        "id": "lxED-RC2EvJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "一方、別の変数gill_colorがbであるかそうでないかのTURE(1) or FLASE(0)で分けることにして、その時にそれぞれ毒がどれくらいいるのか、同じようにクロス集計してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "IR6apIjgEvJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a3308490-52d3-4866-e138-de4be423d5aa"
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.groupby([\"gill_color_b\", \"flg\"])[\"flg\"].count().unstack()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>flg</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gill_color_b</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4208.0</td>\n",
              "      <td>2188.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1728.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "flg                0       1\n",
              "gill_color_b                \n",
              "0             4208.0  2188.0\n",
              "1                NaN  1728.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "6HRWs3ZeEvJR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記の表を見てみると、gill_colorがb(1)であれば毒(1)の数が1728個で毒でない(0)数が0個（ないのでNaN）になります。一方、gill_colorがbでなければ（0）、毒(1)の数が2188個で毒でない(0)数が4208個になります。この結果を見てみると、gill_colorがbであれば確実に毒(1)だとわかるので、毒キノコかどうか判断する有益な情報となりそうです。"
      ]
    },
    {
      "metadata": {
        "id": "gq-zRftEEvJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "先ほどは2つの変数の例（cap_color_cとgill_color_b）で考えましたが、他にもいろいろな変数（cap-shape、他）があるので、それぞれに対して上のような条件分岐を考えることができます。しかし、たくさんある変数の中で、どの変数が有益な情報でどの変数か有益でない情報なのかを見分けるのは、なかなか大変な作業になりそうです。上記の例のように、2つの変数について、明らかに差がある場合はいいですが、それを客観的に判断するには、どうすれば良いでしょうか。さらに、先ほどのように2つだけの比較ならば楽なのですが、変数全ての組み合わせについて見ていくのは、大変そうです。\n",
        "\n",
        "ここで、ある変数が毒キノコを見分けるのに有益な情報であるかどうか、定量化して考えるのが、**エントロピー**や**情報利得**の概念になります。"
      ]
    },
    {
      "metadata": {
        "id": "Ms6FOIdYEvJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **エントロピー**について"
      ]
    },
    {
      "metadata": {
        "id": "4FcrMMYNEvJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずは、**エントロピー**からです。まずは定義式から見ていきましょう。以下の式H(s)がエントロピーの式で、Sはデータの集合、piはそのデータの中に目的とするデータがどれくらいいるのかの割合（確率）を示します。"
      ]
    },
    {
      "metadata": {
        "id": "0vUZEla5EvJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\begin{eqnarray}\n",
        "\\ H(S)= -\\sum^n_{i=1}(p_i\\log_{2}p_i)\n",
        "\\end{eqnarray}"
      ]
    },
    {
      "metadata": {
        "id": "zCVFoDaWEvJW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、エントロピーは、あるデータの集まりについての乱雑さを測る尺度で、情報理論の先駆者クロード・シャノンが発明した概念です。物理学などのエントロピーと似た概念です。"
      ]
    },
    {
      "metadata": {
        "id": "KAg3EQjJEvJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上の式だけ見ていてもわからないと思いますので、ここで少し例を考えてみます。データはクラス分類が2つだけ（毒キノコかそうでないか）で、毒キノコでない割合をp1として、毒キノコである割合をp2とします。\n",
        "\n",
        "ここで1つ目の極端なケースとして、データに毒キノコも、そうでないキノコも等しい割合で入っている場合を考えます。p1=p2=0.5となるので、エントロピーは上の式から以下のようになります。なお、底が2のログ関数(np.log2)を使っています。"
      ]
    },
    {
      "metadata": {
        "id": "qtyLLQu-EvJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae20e8b8-6be6-43cd-e26e-2f79e3700445"
      },
      "cell_type": "code",
      "source": [
        "- (0.5 * np.log2(0.5) + 0.5 * np.log2(0.5))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "vfqmm5NhEvJb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記より、1になっているのがわかります。データとしての乱雑さが最大となる場合は、エントロピーが1となります。毒キノコもそうでないキノコも等しい割合(0.5)で含まれているので、区別できていない状態です。\n",
        "\n",
        "次に考える2つ目のケースとして、毒キノコでない割合がp1=0.001として、毒キノコである割合がp2=0.999であった場合を考えると、エントロピーは以下のようになります。"
      ]
    },
    {
      "metadata": {
        "id": "BHUYos5JEvJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "- (0.001 * np.log2(0.001) + 0.999 * np.log2(0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QIXwkHJcEvJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ほぼ0に近い値になっているのがわかります。データとしての乱雑さが最小となる場合は、エントロピーが0となります。毒キノコである(または毒キノコでない)ということが分かっており、完全に区別できている状態がエントロピー0です。"
      ]
    },
    {
      "metadata": {
        "id": "2eEQphIgEvJl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、今回の例では、クラスは2分類のため p1 = 1 - p2という関係式ができるめ、エントロピーの式は以下のように定義できます。"
      ]
    },
    {
      "metadata": {
        "id": "L904WcGTEvJm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_entropy(p):\n",
        "    return - (p * np.log2(p) + (1 - p) *  np.log2(1 - p) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1syZXq5EvJo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さて、pは確率であるため、0から1までの値を取りますので、このpとエントロピーの式をグラフで表すと以下のようになります。"
      ]
    },
    {
      "metadata": {
        "id": "z3eZAoylEvJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pの範囲を0~1とするとエラーが出るため、少しずらしている\n",
        "# pの値を0.001から0.999まで0.01刻みで動かす\n",
        "p = np.arange(0.001, 0.999, 0.01)\n",
        "\n",
        "# グラフ化\n",
        "plt.plot(p, calc_entropy(p)) \n",
        "plt.xlabel(\"prob\")\n",
        "plt.ylabel(\"entropy\")\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZ384sMLEvJs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記のグラフから、エントロピーは0が最小値で、1が最大値となるのがわかります。エントロピーが1の場合は異なるクラスが等しく混じっている時で、エントロピーが0の場合は全てのデータが同じ分類に属している時です。"
      ]
    },
    {
      "metadata": {
        "id": "eYMlEBAiEvJs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "イメージとして、以下のリンクが参考になります。pを毒キノコでない確率(+)して、H(S)をエントロピーとすると以下のようになります。エントピーが1の時は毒キノコ(-)と毒キノコでない(+)が等しく入り混じっている状態で、エントロピー0の時は、はっきりと区別されている（p=0の時は-のみ、p=1の時は+のみ）のがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "s901VifOEvJs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://image.slidesharecdn.com/decisiontrees-161118165341/95/women-in-data-science-meetup-atx-decision-trees-7-638.jpg?cb=1479488126)\n",
        "参照URL:https://image.slidesharecdn.com/decisiontrees-161118165341/95/women-in-data-science-meetup-atx-decision-trees-7-638.jpg?cb=1479488126"
      ]
    },
    {
      "metadata": {
        "id": "TDC9dOVnEvJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここまでの説明で、エントロピーの式と乱雑さの関係については、だいぶイメージがついたのではないでしょうか。次は、先ほどのキノコの例でエントロピーを計算してみましょう。扱っているデータセット(S)は合計で8124レコードありました。また、先ほど目的となる変数をflg付けしましたので、それぞれのクラスに属するデータをカウントしてみることにします。"
      ]
    },
    {
      "metadata": {
        "id": "k1_-pT76EvJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.groupby(\"flg\")[\"flg\"].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHbOt8wsEvJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上の集計結果から、毒でないキノコ(0)は4208個、毒キノコ(1)は3916個あります。よって、毒キノコでない割合は"
      ]
    },
    {
      "metadata": {
        "id": "TrmFDf52EvJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "4208 / 8124"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhIOxCb7EvJ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "で、0.518となり、毒キノコである割合は、"
      ]
    },
    {
      "metadata": {
        "id": "6Ez4ustoEvJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "3916 / 8124"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QL48Xps7EvKB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "で、0.482となりましたので、これを上のエントピーを使って考えると、i（クラス）は2つあり、p1=0.518で、p2=0.482なのでこれらを代入すると、エントロピーは"
      ]
    },
    {
      "metadata": {
        "id": "kktBvyYqEvKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "- (0.518 * np.log2(0.518) + 0.482 * np.log2(0.482))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9j-FW6SEvKE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "で、0.999となりました。これで、毒キノコとそうでないキノコが入り混じっているのがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "6qrq6jxpEvKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **情報利得**について"
      ]
    },
    {
      "metadata": {
        "id": "vQjyQYcbEvKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さて、エントロピーは1に近づけば近づくほど乱雑さを増し、0になるほどよく分類されている、ということでした。次に考えられることとして、どのようにデータを分類したら、この数字（0.999）をもっと小さくできるのかということです。このエントピーが小さければよいので、その方法を考えます。この考え方が、次に説明する**情報利得**という概念になります。情報利得は、ある変数を使ってデータを分割するときに、全体としてどれだけエントロピーを減少（あるいは増加）させることができるのかを評価するために使います。"
      ]
    },
    {
      "metadata": {
        "id": "cdKKb3R5EvKG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "先ほどと同じcap_color_cとgill_color_bの2つの属性（変数）を使って、どちらが情報として有益なのか、エントロピーや情報利得を使って計算し、考えてみることにします。より情報利得がある方が、有益な情報となります。"
      ]
    },
    {
      "metadata": {
        "id": "8daS5fhHEvKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まず、cap_colorがcであるか、そうでないかを分けたら2つのグループできますので、それぞれにおいて毒キノコの割合を計算して、それぞれのエントロピーを計算すると以下のようになります。"
      ]
    },
    {
      "metadata": {
        "id": "fHFM2ixSEvKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.groupby([\"cap_color_c\", \"flg\"])[\"flg\"].count().unstack()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sOOKLu1mEvKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cap_colorがcでない場合のエントロピー\n",
        "- ( 4176 / (4176 + 3904)* np.log2(4176 / (4176 + 3904)) + 3904 / (4176 + 3904) * np.log2(3904 / (4176 + 3904)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lr7XUIVEvKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# cap_colorがcである場合のエントロピー\n",
        "- ( 32 / (32 + 12)* np.log2(32 / (32 + 12)) + 12 / (32 + 12) * np.log2(12 / (32 + 12)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YKU5AK-EvKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さて、分割する前の全体のエントロピーは0.999でした。ここで分割する前のデータを親データセットとよび、先ほど分割したデータを子のデータセットと呼びます。\n",
        "\n",
        "情報利得を「**親データセットのエントロピー - Σ{(子データセットのサイズ/親データセットのサイズ)×子のデータセットのエントロピー}**」と定義します。ここからこの値が大きければ大きいほど、より有益な情報であるというのがわかります。情報利得が小さいと親データセットとほとんどエントロピーが変わらないので、それほど有益な情報でないと判断します。\n",
        "\n",
        "まず、Σ{(子データセットのサイズ/親データセットのサイズ)×子のデータセットのエントロピー}を計算すると以下のようになります。"
      ]
    },
    {
      "metadata": {
        "id": "kOx7ZX36EvKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(4176 + 3904) / 8124 * 0.999 + (32 + 12) / 8124 * 0.845"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CflFuAzHEvKj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "よって、情報利得は以下になります。"
      ]
    },
    {
      "metadata": {
        "id": "CPScvmosEvKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "0.999 - 0.998"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIc7axSxEvKn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "情報利得は0.001であまりエントロピーは減少していないことがわかり、それほど有益な情報ではなさそうということがわかります。\n",
        "\n",
        "一方、gill_colorがbであるかどうかの情報利得を計算しましょう。"
      ]
    },
    {
      "metadata": {
        "id": "VQRsPvexEvKo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mush_data_dummy.groupby([\"gill_color_b\", \"flg\"])[\"flg\"].count().unstack()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZDFebtkEvKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gill_colorがbでない場合のエントロピー\n",
        "- ( 4208 / (4208 + 2188)* np.log2(4208 / (4208 + 2188)) + 2188 / (4208 + 2188) * np.log2(2188 / (4208 + 2188)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0aO_zgFEvKv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gill_colorがbである場合のエントロピー\n",
        "- (0 + 1728 / (0 + 1728) * np.log2( 1728 / (0 + 1728)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-YduUsgKEvKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次に、Σ{(子データセットのサイズ/親データセットのサイズ)×子のデータセットのエントロピー}を計算すると以下のようになります。"
      ]
    },
    {
      "metadata": {
        "id": "VvM2SNX1EvKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(4208 + 2188) / 8124 * 0.927 + (0 + 1728) / 8124 * 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sceK2dGyEvK0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "よって、先ほどと同じように親データセットのエントロピーから上の計算結果を引くと、情報利得は以下になります。"
      ]
    },
    {
      "metadata": {
        "id": "F1Uxlzg-EvK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "0.999 - 0.73"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsxl0lTbEvK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "情報利得は0.269となりました。"
      ]
    },
    {
      "metadata": {
        "id": "cM3Ho7yIEvK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以上より、情報利得について、cap_color_cの場合は0.01で、gill_color_bの場合が0.269になり、gill_color_bの方がよりエントロピーが減少していましたので、gill_color_bが属性として、より情報価値があるというのがわかります（実際に、毒キノコであるかどうかわかったのは、gill_colorがbであるかそうでないかでした）。\n",
        "\n",
        "これを繰り返して計算し、情報利得が一番大きいものが一番有益な属性情報として判断されます。そしてさらに、条件分岐を実施して枝分かれさせていくのが、このエントロピーによる決定木の計算ロジックになります。上の例では、gill_colorがbであるかどうかを判断した後、bである場合はそこで完全に毒キノコかどうかわかりストップできますが、bでない場合は毒キノコでない数は4208個、毒キノコの数は2188なので、そこからまたある属性を使って条件分岐させていき、それを繰り返して計算するイメージです。"
      ]
    },
    {
      "metadata": {
        "id": "nL9T4PibEvK3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "補足として、上記の例では、エントロピーを使ってきましたが、決定木で条件分けをするための他の指標としては、**ジニ不純度、分類誤差（誤分類率）**など色々な手法があります。ジニ不純度は、確率・統計の総合問題で出てきたジニ係数と関わりがあり、「不平等指数」として扱い、偏りが生じるている時はジニ係数が1に近づき、みんな同じような感じであれば、0に近づきました。ジニ不純度もこの考え方と同じです。他、分類誤差などもありますが、指標の詳細な説明については、後で紹介する参考文献等を見てください。\n"
      ]
    },
    {
      "metadata": {
        "id": "iZ2LVnsSEvK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考URL]\n",
        "\n",
        ">http://blogs.teradata.com/international/ja/hhg14/"
      ]
    },
    {
      "metadata": {
        "id": "RrNTWIb4EvK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**[やってみよう]**\n",
        "\n",
        ">ジニ不純度、分類誤差（誤分類率）について調べてみましょう。それぞれどんな指標でしょうか。また実装はどうすればいいでしょうか。"
      ]
    },
    {
      "metadata": {
        "id": "kGAB6ic5EvK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "11.2.3項（正則化、ラッソ回帰、リッジ回帰）において、モデルの複雑さに関してコメントしましたが、決定木の場合、モデルの複雑さは分岐数で決定されます。多く分岐すればするほど複雑なモデルになります。"
      ]
    },
    {
      "metadata": {
        "id": "BHTpRQhsEvK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **決定木**の実装"
      ]
    },
    {
      "metadata": {
        "id": "Iy5WnVJoEvK5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さて次は、決定木のモジュールとしてDecisionTreeClassifier（分類木）を使い、分岐数の決定にエントロピーを設定します。いつもと同じように、訓練データとテストデータと分けてモデルを構築し、スコアを見てみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "BHZiysujEvK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの分類\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 決定木\n",
        "from sklearn import tree\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "\n",
        "# 説明変数と目的変数\n",
        "X = mush_data_dummy.drop(\"flg\", axis=1)\n",
        "Y = mush_data_dummy['flg']\n",
        "\n",
        "# 学習データとテストデータに分ける\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, random_state=50)\n",
        "\n",
        "# 決定木インスタンス（エントロピー、深さ5）\n",
        "tree_model = DecisionTreeClassifier(criterion='entropy',max_depth=5, random_state=50)\n",
        "\n",
        "tree_model.fit(X_train,y_train)\n",
        "\n",
        "print(\"train:\",tree_model.__class__.__name__ ,tree_model.score(X_train,y_train))\n",
        "print(\"test:\",tree_model.__class__.__name__ , tree_model.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtotJYAtEvK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "結果としては、テストデータで88%ほどの正解率です。決定木の分類数決定のパラメータとして、他、max_depthがあり、上では5にしています。深さは条件分岐の数と思っていただければ良いです。決定木はモデルを構築する際に、他のモデルなどでやる標準化や正規化などのデータの前処理は、基本的に必要ありません。ただし、決定木は、分岐数が多い場合に、後で述べる過学習という、モデルの汎化性が失われてしまうことが多いので、気をつけましょう。"
      ]
    },
    {
      "metadata": {
        "id": "VT-NRjbJEvK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**注意：以下2つのセルは、現在(2017/5/3時点)ilect上では実行できませんので、注意してください。今回は参考情報として見てください。（余力のある方は、terminalから環境を構築したり、ローカルで環境を構築してみてください。）**\n",
        "\n",
        "参考ですが、以下のように可視化することもできます。条件分岐をして、木の形になっているのがイメージできると思います。これが決定木といわれる所以です。ただ、エンコードしているため、少し数値でわかりにくいですが、読み方として具体的には、一番上の変数（X[0]、ここでは説明変数の1番目のカラムのgill_color_b）が0.5より大きいときには右のFalseに進み、その子データセットのサンプル数は1284になり、エントロピーは0になりますので、完全に分かれて（毒かそうでないか）いるのがわかります。つまり、gill_color_bのフラグが1（X[0]<=0.5はFalseになる）のときは、毒になります。"
      ]
    },
    {
      "metadata": {
        "id": "SQ3ogy0iEvK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pydotplus\n",
        "from sklearn.externals.six import StringIO\n",
        "from IPython.display import Image\n",
        "\n",
        "dot_data = StringIO()\n",
        "tree.export_graphviz(tree_model, out_file=dot_data)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SAoUVnBYEvLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image(graph.create_png())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Z70A7QOEvLD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以下は、この決定木を説明するのに、参考にした文献になります。以前にも紹介しましたが、わかりやすく書いてあるので、オススメです。"
      ]
    },
    {
      "metadata": {
        "id": "WzCfgp_uEvLE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">[参考文献]\n",
        "\n",
        ">『戦略的データサイエンス入門 ―ビジネスに活かすコンセプトとテクニック』（Foster Provost (著), Tom Fawcett (著), 竹田 正和(監訳) (翻訳), 古畠 敦 (翻訳), & 8 その他、オライリージャパン）\n",
        "\n",
        ">[参考URL]\n",
        "\n",
        ">http://www.data-science-for-biz.com/DSB/Home.html"
      ]
    },
    {
      "metadata": {
        "id": "EPIBtljLEvLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 1>\n",
        "分析対象データとして、sklearnのdatasetsからload_breast_cancerを読み込んで、目的変数をcancer.target、説明変数をcancer.dataとして、決定木のモデルを使って、予測と検証を実施してください。パラメータや深さなどを変更してみて、モデリングしてください。"
      ]
    },
    {
      "metadata": {
        "id": "2YQditjCEvLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.6 k-NN\n",
        "ゴール：k-NN,怠惰学習,memory-based learning,Look-Alike model"
      ]
    },
    {
      "metadata": {
        "id": "Q04FSx15EvLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次は、**k-NN（k近傍法）**について学びます。これは例えば、あるグループAとグループBがあり、その人たちの属性がわかっているとして、どちらのグループに属するか分からない新しい人が来たケースを考えます。ここで、その人がAとBのどちらのグループに属するか考える際に、その人と属性が近い人はグループAの中に多く含まれるのか、それともグループBに多く含まれるのかを多数決で決めます。その上で、属性が近い人がより多く含まれるグループに、その新しい人が属していると判断します。kとは、多数決に利用する人数となります。k-NNは怠惰学習やmemory-based learningとも言われ、訓練データをそのまま覚えて学習する方法です。\n",
        "\n",
        "以下は、参照URLにあるイメージです。緑の丸がAグループ、青の丸がBグループとして、赤の丸がどちらのグループか判断することを考えます。k=3の場合に、Aグループが近い人が2名、Bグループに近い人が1名なので、この赤の人はAグループに属すると判断します。さらにkを増やしk=7の場合は、Aグループが近い人が3名、Bグループに近い人が4名なので、この緑の人はBグループに属すると判断します。このようにkの値によって結果が変わるので注意しましょう。\n",
        "\n",
        "なお、k-NN法は、マーケティングの世界ではLook-Alikeモデルとも言われ、属性が似ている人たちを集めて判断して、それぞれの属性に合ったアプローチを仕掛けていきます。"
      ]
    },
    {
      "metadata": {
        "id": "btZ3TGeJEvLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![comment](http://www.nag-j.co.jp/nagdmc/img/knn.gif)"
      ]
    },
    {
      "metadata": {
        "id": "PbOLpXV8EvLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL：http://www.nag-j.co.jp/nagdmc/img/knn.gif"
      ]
    },
    {
      "metadata": {
        "id": "ciQVecFLEvLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "次は実装で、k-NN法はKNeighborsClassifierを使います。ここでは、kをパラメータ化して、1から10まで変化させて、訓練データとテストデータのスコアの変化を見ています。kが小さい時は、このスコアに乖離がありますが、また6を超えたあたりからまた乖離が生じて、過学習になっているのがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "D1mf3gMDEvLI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# k-NN \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.neighbors import  KNeighborsClassifier\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cancer.data, cancer.target, stratify = cancer.target, random_state=66)\n",
        "\n",
        "training_accuracy = []\n",
        "test_accuracy =[]\n",
        "\n",
        "neighbors_settings = range(1,11)\n",
        "for n_neighbors in neighbors_settings:\n",
        "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    clf.fit(X_train,y_train)\n",
        "    \n",
        "    training_accuracy.append(clf.score(X_train, y_train))\n",
        "    \n",
        "    test_accuracy.append(clf.score(X_test, y_test))\n",
        "    \n",
        "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"n_neighbors\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kj0KU506EvLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、k-NNは目的変数が連続の場合（回帰）でも実施できます。"
      ]
    },
    {
      "metadata": {
        "id": "6w0DT6f0EvLM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**[やってみよう]**\n",
        "\n",
        ">k-NNの回帰はどうやって計算されるでしょうか。また、どのように実装するでしょうか。調べて実装してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "DAbjI17bEvLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 1>\n",
        "以前扱ったキノコのデータに対して、k-NNを使ってモデリングして、検証してみましょう。kパラメータを変更しながら実行してください。"
      ]
    },
    {
      "metadata": {
        "id": "MgEVSTdWEvLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 2>\n",
        "以前、記述統計学で使ったデータ（学生のテスト結果と属性データ、student-mat.csv）を用いて、目的となる変数をG3、説明変数となる属性データを以下のようにして、k-NNのkパラメータを変えながら、どのkが最適か考えてみましょう。ただし、目的変数は数値型で、回帰となりますので、KNeighborsRegressorを使ってください。回帰の場合、出力される値は近傍のk個のデータの平均になります。"
      ]
    },
    {
      "metadata": {
        "id": "Di0lVu-5EvLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.7 サポートベクターマシン\n",
        "ゴール：サポートベクターマシン"
      ]
    },
    {
      "metadata": {
        "id": "CFVEcMJ2EvLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**サポートベクターマシン(SVM)**は、訓練データにおいて、他クラスの中で最も近い位置にあるサポートベクタを基準として、距離（マージン）が最も大きくなるように境界線を引く方法です。イメージとしては、以下の参照URLがわかりやすいです。以下の2つのグループを分ける境界線は色々とあるのですが、以下のマージン(距離)が一番大きくなるように計算します。簡単に言うと、あるグループを分けるときに、いろいろと境界線は引けるけど、お互いからなるべく遠いところに境界線を引いた方がいいよねという考え方です。"
      ]
    },
    {
      "metadata": {
        "id": "2GZiUc87EvLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![comment](http://www.jepoc.or.jp/upload/lib_data/120513120351.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "bwmL5zUSEvLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL：http://www.jepoc.or.jp/upload/lib_data/120513120351.jpg"
      ]
    },
    {
      "metadata": {
        "id": "NkE7WV0IEvLQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "モジュールはsklearn.svmのLinearSVCを使います。分類問題です。なお、データはcancerを使います。"
      ]
    },
    {
      "metadata": {
        "id": "2QPx7pO1EvLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cancer.data, cancer.target, stratify = cancer.target, random_state=50)\n",
        "\n",
        "model = LinearSVC()\n",
        "clf = model.fit(X_train,y_train)\n",
        "print(\"train:\",clf.__class__.__name__ ,clf.score(X_train,y_train))\n",
        "print(\"test:\",clf.__class__.__name__ , clf.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNN3etulEvLV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "なお、ここでもスケーリング（標準化）をやったあとにモデリングをしてみます。スコアが改善していることがわかります。"
      ]
    },
    {
      "metadata": {
        "id": "AkIdVtKsEvLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# 標準化のためのモジュール\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cancer.data, cancer.target, stratify = cancer.target, random_state=50)\n",
        "\n",
        "model = LinearSVC()\n",
        "\n",
        "# 標準化\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "clf = model.fit(X_train_std,y_train)\n",
        "print(\"train:\",clf.__class__.__name__ ,clf.score(X_train_std,y_train))\n",
        "print(\"test:\",clf.__class__.__name__ , clf.score(X_test_std,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_SJZhmxEvLX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記は、分類問題でしたが、回帰でもサポートベクターマシンは使えますので、調べてみてください。"
      ]
    },
    {
      "metadata": {
        "id": "qBkPEmGCEvLX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**[やってみよう]**\n",
        "\n",
        ">サポートベクターマシンで回帰を実施する（連続変数を予測する）場合は、どうやって実装するでしょうか。調べてみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "yPPEJqAyEvLY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以上で、教師あり学習は終わりになります。それぞれの手法についてあまり深くは立ち入りませんでしたが、実際に実務に使う段階になったら調べてみてください。練習問題、総合問題が終わった後は教師なし学習になります。"
      ]
    },
    {
      "metadata": {
        "id": "pvI_QUV2EvLZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  <練習問題 1>\n",
        "cancerデータについて、モジュールはsklearn.svmのSVCを使って、cancer.targetを予測するモデルを構築しましょう。model = SVC(kernel='rbf', random_state=0, C=2)としてください。前と同じように、訓練データとテストデータに分けて、標準化してスコアをチェックしてください。"
      ]
    },
    {
      "metadata": {
        "id": "pzac4lqTEvLZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 11.8 総合問題"
      ]
    },
    {
      "metadata": {
        "id": "r0UrIaE6EvLZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.8.1 総合問題1\n",
        "\n",
        "教師あり学習に関する用語について、それぞれの役割や意味について述べてください。どのような場面で使いますか？ネットや参考文献等も使って調べてみてください。\n",
        "- 回帰\n",
        "- 分類\n",
        "- 教師あり学習\n",
        "- 重回帰分析\n",
        "- ロジスティック回帰分析\n",
        "- 正則化\n",
        "- リッジ回帰\n",
        "- ラッソ回帰\n",
        "- 決定木\n",
        "- エントロピー\n",
        "- 情報利得\n",
        "- k-NN法\n",
        "- SVM"
      ]
    },
    {
      "metadata": {
        "id": "ByHYMksVEvLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.8.2 総合問題2\n",
        "分析対象データとして、sklearnのdatasetsからload_iris(アヤメの花)を読み込んで、目的変数をiris.target、説明変数をiris.dataとして、決定木のモデルを使って、予測と検証を実施してください。目的変数のデータはアヤメの花の種類で、以下の参照URLを見てどんな種類があるのかイメージしてください。"
      ]
    },
    {
      "metadata": {
        "id": "CHwxVok8EvLa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの分類\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 分析対象データ\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# 決定木\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# data\n",
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HqGgJNMbEvLc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![comment](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/iris-machinelearning.png)"
      ]
    },
    {
      "metadata": {
        "id": "9_Yr1BN_EvLd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "参照URL:https://s3.amazonaws.com/assets.datacamp.com/blog_assets/iris-machinelearning.png"
      ]
    },
    {
      "metadata": {
        "id": "nPYTuIt5EvLd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 11.8.3 総合問題3\n",
        "\n",
        "同じデータ(load_breast_cancer()など)に対して、ロジスティック回帰分析やSVMなど今まで学んだモデルを試し、どれが一番スコアが高いでしょうか？ また、データによって、一番良いスコアが出るモデルは異なりますが、その特徴はどんなものか、考察してください。（これをノーフリーランチといい、どんなデータに対しても、一番良いモデルになるモデルはないということを意味します。）"
      ]
    }
  ]
}